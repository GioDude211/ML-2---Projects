{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmer: Giovanni Vecchione\n",
    "## Date: 4/8/24\n",
    "## Subject: Machine Learning 2 - Autoencoders, GANS, and Diffusion Models\n",
    "\n",
    "Chapter 17. Autoencoders, GANs, and Diffusion Models\n",
    "\n",
    "Goal: Use Generative Adversarial Networks (GAN) to build the project. Submit your project as Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Generative Adversarial Network (GAN)?\n",
    "\n",
    "### **The Art of Imitation:** GANs are a type of deep learning architecture where two neural networks are locked in an elaborate game of cat-and-mouse.  Think of them as a master art forger and an expert art critic:\n",
    "   **The Generator:** The 'art forger' responsible for creating realistic fakes that could pass as authentic pieces (e.g., images, music, text etc.).\n",
    "     \n",
    "   **The Discriminator:**  The 'art critic'  trained to tell the difference between a genuine masterpiece and the generator's forgeries.\n",
    "\n",
    "### **A Competitive Game:**  Both networks get better through this competition.  The generator keeps refining its fakes to fool the discriminator, and the discriminator gets better at spotting the subtle flaws in those fakes. Over time, the generator gets so good that its creations become indistinguishable from real data.\n",
    "\n",
    "## Basic Concepts\n",
    "\n",
    "1. **Unsupervised Learning:** GANs don't need labeled data. They learn from a dataset of examples (e.g., a collection of real photographs), extracting the patterns and underlying structure without explicit labels like \"dog\" or \"cat.\"\n",
    "\n",
    "2. **Generator Network:**\n",
    "   * Takes random noise as input.\n",
    "   * Tries to transform that noise into data that resembles the real examples it has seen.\n",
    "   * Its goal is to make the discriminator believe its outputs are real.\n",
    "\n",
    "3. **Discriminator Network:**\n",
    "   * Takes as input both real data samples and the generator's outputs.\n",
    "   * Tries to classify whether an input is \"real\" (from the training dataset) or \"fake\" (created by the generator).\n",
    "   * Gives feedback to the generator to help it improve its fakes.\n",
    "\n",
    "4. **Adversarial Training:**\n",
    "   * The generator and discriminator are trained simultaneously.\n",
    "   * The generator improves by making the discriminator's job harder.\n",
    "   * The discriminator improves by becoming a better judge of authenticity.\n",
    "   * It's this constant push-and-pull that makes GANs so powerful.\n",
    "\n",
    "**Why use GANs?**\n",
    "\n",
    "* **Generating New Data:** Create realistic images, music, videos, or other data forms that weren't in your original dataset.\n",
    "* **Data Augmentation:** Increase the size and diversity of a dataset, useful in areas where real data is scarce.\n",
    "* **Image-to-Image Translation:** Change images from one style to another (e.g., turning sketches into photos).\n",
    "* **Super Resolution:** Enhancing image or video quality.\n",
    "\n",
    "**Ready to Build?**\n",
    "\n",
    "Building a GAN involves:\n",
    "\n",
    "* **Choosing Your Domain:**  Images, text, audio, etc.\n",
    "* **Data Preparation:**  Gathering or creating a suitable dataset.\n",
    "* **Network Architecture:**  Designing your generator and discriminator networks (often using convolutional neural networks for images).\n",
    "* **Training Setup:**  Defining the loss functions that guide the networks and selecting an optimization algorithm. \n",
    "* **Implementation:**  Coding your GAN using a deep learning framework like TensorFlow or PyTorch.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from keras.regularizers import l1\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import backend as K \n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "#Checks if GPU is being used\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use the GPU\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0)) \n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU\n",
    "    print(\"GPU not available, using CPU.\")\n",
    "\n",
    "#Using GPU: NVIDIA GeForce GTX 1660 SUPER - Successful\n",
    "#NOTE: This took some time to set up by installing and pathing the cuda toolkit v.12.4 and the right supplemental packages. This drastically improved\n",
    "#training time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
