{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1_1\n",
    "\n",
    "## Programmer: Giovanni Vecchione\n",
    "## Date: 4/24/24\n",
    "\n",
    "## Subject: Machine Learning 2 - Capstone Project\n",
    "* ### Dungeons and Dragons Narrative Model\n",
    "\n",
    "\n",
    "## Structure:\n",
    "* ### *Focusing on the NLP model for the Capstone Project due to time constraints.*\n",
    "* ### NLP component that can interpret spoken D&D commands and classify them into game-specific intents.\n",
    "\n",
    "## Status: In-Progress\n",
    "\n",
    "## Hypotheses:\n",
    "* ### By using a combination of text normalization, feature engineering, and appropriate classifcation models, I can achieve an accuracy of at least 80% on identifying D&D intents from spoke commands.\n",
    "\n",
    "## Data Colletion:\n",
    "* ### Define a focused set of D&D commands and generate some commands using spoken word w/ variation.\n",
    "\n",
    "## Preprocessing:\n",
    "* ### Speech-to-text - Need text transcripts.\n",
    "* ### Text Normalization - Clean up the transcripts by removing filler words.\n",
    "\n",
    "## Feature Engineering:\n",
    "* ### Bag-of-Words to start and then add word embeddings and/or specialized features.\n",
    "\n",
    "## Model Selection:\n",
    "* ### Neural Network - RNN\n",
    "\n",
    "## Evaluation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mtp\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "#Checks if GPU is being used\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use the GPU\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0)) \n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU\n",
    "    print(\"GPU not available, using CPU.\")\n",
    "\n",
    "#Using GPU: NVIDIA GeForce GTX 1660 SUPER - Successful\n",
    "#NOTE: This took some time to set up by installing and pathing the cuda toolkit v.12.4 and the right supplemental packages. This drastically improved\n",
    "#training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Cornell Movie-Dialogs Corpus\n",
    "* Pre-train on general text datasets.\n",
    "* Introduce specific DND texts.\n",
    "* Fine tune for intents using DND terms.\n",
    "\n",
    "Here's the challenge: I need to transform this conversational data into a format where I have \"command-like\" examples to train the intent classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading movie-corpus to C:\\Users\\GioDude\\.convokit\\downloads\\movie-corpus\n",
      "Downloading movie-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip (40.9MB)... Done\n"
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "corpus = Corpus(filename=download(\"movie-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very good.\n",
      "This is a nice place.  It must have cost a pretty penny.\n",
      "Sure, Mickey.  Sure.\n",
      "Yes, sir.  They are indeed.\n",
      "Let's go by Rosarita's. You been there yet?\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    all_utterance_ids = corpus.get_utterance_ids()\n",
    "    random_id = random.choice(all_utterance_ids)\n",
    "    utterance = corpus.get_utterance(random_id)\n",
    "    print(utterance.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store our training data (command, intent) pairs\n",
    "all_data = []\n",
    "\n",
    "for utterance in corpus.get_utterance_ids():  # Iterate through all utterances\n",
    "    text = corpus.get_utterance(utterance).text  # Get the utterance text\n",
    "    # Consider replacing 'command' with a more specific D&D intent later \n",
    "    all_data.append((text.lower(), 'command'))  # Append to training data (text, intent)\n",
    "\n",
    "#NOTE : This is a simple transformation so that addresses each line as a command, saves time. However I may change this \n",
    "#to be selective so that it actually searches for specific training commands for DND."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
